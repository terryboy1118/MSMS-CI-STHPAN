import numpy as np
import pandas as pd
import torch
from joblib import Parallel, delayed
import torch.nn.functional as F
from tqdm import tqdm

# 1. **è®€å– eod_data**
train_path = "/home/adam/CI-STHPAN-main/CI-STHPAN_self_supervised/nyse_all/nyse_eod/eod_data_train.npy"
valid_path = "/home/adam/CI-STHPAN-main/CI-STHPAN_self_supervised/nyse_all/nyse_eod/eod_data_valid.npy"

eod_train = np.load(train_path)  # (1026, 756, 5)
eod_valid = np.load(valid_path)  # (1026, 764, 5)
print(eod_train.shape)
print(eod_valid.shape)

# 2. **è®€å– tickers**
tickers_path = "/home/adam/CI-STHPAN-main/CI-STHPAN_self_supervised/src/data/datasets/stock/NYSE_tickers_qualify_dr-0.98_min-5_smooth.csv"
tickers = pd.read_csv(tickers_path, header=None).squeeze("columns").tolist()
assert len(tickers) == 1737, f"è‚¡ç¥¨æ•¸é‡éŒ¯èª¤ï¼Œæ‡‰ç‚º 1026ï¼Œå¯¦éš›ç‚º {len(tickers)}"

# 3. **è®€å–è½‰æŠ˜é»**
turning_points_dir = "/home/adam/CI-STHPAN-main/CI-STHPAN_self_supervised/nyse_all/nyse_turning/"
turning_points_dict = {
    ticker: np.load(f"{turning_points_dir}NYSE_{ticker}_turning_points.npy", allow_pickle=True).tolist()
    for ticker in tickers
}

# 4. **éæ¿¾æ‰è¶…é eod_train é•·åº¦ (755) çš„è½‰æŠ˜é»**
max_time_index = eod_valid.shape[1]  # 756
filtered_turning_points_dict = {
    ticker: sorted([t for t in turning_points_dict[ticker] if t <= max_time_index - 1] + [max_time_index - 1])
    for ticker in tickers
}

def gpu_dtw(A, B):
    """ä½¿ç”¨ PyTorch GPU è¨ˆç®— DTW"""
    if len(A) == 0 or len(B) == 0:
        return np.nan  # é¿å…ç©ºåºåˆ—å°è‡´éŒ¯èª¤

    A_gpu = torch.tensor(A, device='cuda', dtype=torch.float32).unsqueeze(0).unsqueeze(0)
    B_gpu = torch.tensor(B, device='cuda', dtype=torch.float32).unsqueeze(0).unsqueeze(0)

    with torch.no_grad():
        dtw_matrix = F.smooth_l1_loss(A_gpu, B_gpu, reduction='sum')  # è¿‘ä¼¼ DTW
    return dtw_matrix.item()

def generate_merged_intervals(turning_points):
    """
    ä¾æ“šè½‰æŠ˜é»ç”¢ç”Ÿåˆä½µå€é–“ï¼Œå¾ç›¸é„°è½‰æŠ˜é»é–‹å§‹ï¼Œé€å±¤åˆä½µï¼Œç›´åˆ°æ¶µè“‹æ‰€æœ‰è½‰æŠ˜é»
    """
    merged_intervals = []
    current_layer = [[turning_points[i], turning_points[i+1]] for i in range(len(turning_points)-1)]

    while len(current_layer) > 1:
        merged_intervals.append(current_layer)

        # **ä¸‹ä¸€å±¤åˆä½µ**
        next_layer = []
        for i in range(0, len(current_layer) - 1, 2):
            merged_section = list(set(current_layer[i] + current_layer[i+1]))  # åˆä½µç›¸é„°å…©çµ„
            merged_section.sort()  # ç¢ºä¿é †åºæ­£ç¢º
            next_layer.append(merged_section)

        # **å¦‚æœå‰©ä¸‹ä¸€å€‹ï¼Œç›´æ¥åŠ å…¥**
        if len(current_layer) % 2 == 1:
            next_layer.append(current_layer[-1])

        current_layer = next_layer

    # æœ€å¾Œä¸€å±¤æ‡‰è©²æ˜¯å®Œæ•´è½‰æŠ˜é»ç¯„åœ
    merged_intervals.append([turning_points])

    return merged_intervals
# **åˆå§‹åŒ– 5 Ã— 1026 Ã— 1026 çŸ©é™£**
dtw_matrix = np.full((5, 1737, 1737), float("inf"))  # åˆå§‹å€¼ç‚ºç„¡çª®å¤§

for feature_idx in range(5):  
    print(f"ğŸ”„ è¨ˆç®— Feature {feature_idx} çš„ DTW ç›¸ä¼¼åº¦...")

    for k in tqdm(range(1737), desc=f"Feature {feature_idx} - è‚¡ç¥¨è¿´åœˆ"):
        benchmark_ticker = tickers[k]
        benchmark_turning_points = filtered_turning_points_dict[benchmark_ticker]

        if len(benchmark_turning_points) < 2:
            continue  # å¦‚æœè½‰æŠ˜é»å¤ªå°‘ï¼Œè·³é

        merged_intervals = generate_merged_intervals(benchmark_turning_points)

        # 7. **è¨ˆç®— DTW**
        for intervals in merged_intervals:
            for interval in intervals:
                if len(interval) < 2:
                    continue  # é¿å…å€é–“é•·åº¦ä¸è¶³

                start, end = interval[0], interval[-1]  # **æ¯å€‹å€é–“çš„èµ·é» & çµ‚é»**
                if end >= eod_valid.shape[1]:  # æª¢æŸ¥ç´¢å¼•æ˜¯å¦è¶…å‡ºç¯„åœ
                    continue

                # **å–å¾—åŸºæº–è‚¡ç¥¨ Feature å€¼**
                A_segment = eod_valid[k, start:end+1, feature_idx]

                if A_segment.shape[0] == 0:
                    continue  # é¿å…ç©ºåºåˆ—éŒ¯èª¤
                max_val = np.max(A_segment)
                min_val = np.min(A_segment)
                range_percent = (max_val - min_val) / (min_val + 1e-8)  # é¿å…é™¤ 0
                                # **å¦‚æœè®Šå‹•éå° (<10%)ï¼Œå‰‡è·³é**
                if range_percent < 0.1:
                    continue
                # **é€ç­†è¨ˆç®— GPU DTW**
                for i in range(1737):
                    if i == k:
                        dtw_matrix[feature_idx, k, i] = 0  # è‡ªå·±çš„ DTW è¨­ç‚º 0
                        continue  # è·³éè‡ªå·±

                    B_segment = eod_valid[i, start:end+1, feature_idx]

                    if B_segment.shape[0] == 0:
                        continue  # é¿å…ç©ºåºåˆ—éŒ¯èª¤

                    score = gpu_dtw(A_segment, B_segment)
                    interval_length = end - start + 1  # è¨ˆç®—å€é–“é•·åº¦
                    normalized_score = score / interval_length  # æ¨™æº–åŒ–

                    # **æ›´æ–°æœ€å° DTW å€¼**
                    dtw_matrix[feature_idx, k, i] = min(dtw_matrix[feature_idx, k, i], normalized_score)
                    #print(dtw_matrix)

# **å„²å­˜çµæœ**
np.save("dtw_valid_matrix.npy", dtw_matrix)

print(f"âœ… DTW è¨ˆç®—å®Œæˆï¼Œçµæœå·²å„²å­˜è‡³ dtw_valid_matrix")